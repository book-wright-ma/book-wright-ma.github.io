<HTML>
  
<HEAD>
  <TITLE> Lecture Slides for the Book of Wright and Ma</TITLE>  
</HEAD>

  <BODY>  

<center>
  <h2> Lecture Slides for Berkeley EECS 208, Fall 2021</h2>
  <h2> by Yi Ma </h2>
</center>

<b>
<ul>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_1.pdf"> Lecture_1.pdf (Introduction)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_2.pdf"> Lecture_2.pdf (Sparse Models)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_3.pdf"> Lecture_3.pdf (Relaxing the Sparse Recovery Problem) </a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_4.pdf"> Lecture_4.pdf (Convex Methods for Sparse Recovery)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_5.pdf"> Lecture_5.pdf (Convex Methods: Towards Stronger Correctness Results)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_6.pdf"> Lecture_6.pdf (Convex Methods: Matrices with Restricted Isometry Property)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_7.pdf"> Lecture_7.pdf (Convex Methods: Noisy Observations and Approximate Sparsity)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_8.pdf"> Lecture_8.pdf (Convex Methods: Phase Transition in Sparse Recovery)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_9.pdf"> Lecture_9.pdf (Low-Rank Matrix Recovery: Random Measurements)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_10.pdf"> Lecture_10.pdf (Low-Rank Matrix Recovery: Matrix Completion)</a>. <br>  
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_11.pdf"> Lecture_11.pdf (Decomposing Low-Rank and Sparse: Principal Component Pursuit)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_13.pdf"> Lecture_13.pdf (Unconstrained Convex Optimization for Structured Data)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_14.pdf"> Lecture_14.pdf (Constrained and Scalable Convex Optimization for Structured Data)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_15.pdf"> Lecture_15.pdf (Nonconvex Methods: Dictionary Learning)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_16.pdf"> Lecture_16.pdf (Nonconvex Methods: Dictionary Learning via l4 Maximization)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_17.pdf"> Lecture_17.pdf (Nonconvex Optimization: First Order Methods)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_18.pdf"> Lecture_18.pdf (Nonconvex Optimization: Power Iteration and Fixed Point)</a>. <br>  
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_19.pdf"> Lecture_19.pdf (Structured Nonlinear Models: Sparsity in Convolution and Deconvolution)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_20.pdf"> Lecture_20.pdf (Structured Nonlinear Models: Transform Invariant Low-Rank Texture)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_21_22.pdf"> Lecture_21_22.pdf (ReduNet: White-Box Deep (Convolution) Networks from
the Principle of Rate Reduction) </a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_23.pdf"> Lecture_23.pdf (Closed-Loop Data Transcription to an LDR via Minimaxing Rate Reduction)</a>. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/2018April-MaYi.pdf"> Slides of a comprehensive presentation on low-rank models</a>. <br>  
</ul>
    </b>  
 
<p>
  <b>  Note:</b> slides for Lecture_12 (about analysis and proof of Principal Component Pursuit) are missing as they had not been made. We will add them later.
    </p>
  </BODY>
</HTML>
