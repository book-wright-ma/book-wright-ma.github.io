<HTML>
  
<HEAD>
  <TITLE> Lecture Slides for the Book of Wright and Ma</TITLE>  
</HEAD>

  <BODY>  

<center>
  <h2> Lecture Slides for Berkeley EECS 208, Fall 2021</h2>
  <h2> by Yi Ma </h2>
</center>

<p>
<i> Be prepared for a journey from convex to nonconvex; from linear to nonlinear; from shallow to deep; from idealistic to realistic; and from theoretical to practical. 
At a more technical and computational level, this is also a journey from L0, to L1, and to L4; and from low-rank, to nuclear norm, and to log-det.</i> The lectures are 
  intentionally organized into several modules, making it easier for future teachers to customize them to courses with different focus, scope, and depth.
</p>  
    
<b>
<ul>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_1.pdf"> Lecture 01</a>: Introduction: Background, History, and Overview. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_2.pdf"> Lecture 02</a>: Sparse Models and L0 Minimization. <br> 
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_3.pdf"> Lecture 03</a>: Relaxing the Sparse Recovery Problem via L1 Minimization. <br><br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_4.pdf"> Lecture 04</a>: Convex Methods for Correct Sparse Recovery. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_5.pdf"> Lecture 05</a>: Convex Sparse Recovery: Towards Stronger Correctness Results. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_6.pdf"> Lecture 06</a>: Convex Sparse Recovery: Matrices with Restricted Isometry Property. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_7.pdf"> Lecture 07</a>: Convex Sparse Recovery: Noisy Observations and Approximate Sparsity. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_8.pdf"> Lecture 08</a>: Convex Sparse Recovery: Phase Transition in Sparse Recovery. <br><br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_9.pdf"> Lecture 09</a>: Convex Low-Rank Matrix Recovery: Random Measurements. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_10.pdf"> Lecture 10</a>: Convex Low-Rank Matrix Recovery: Matrix Completion. <br>  
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_11.pdf"> Lecture 11</a>: Convex Low-Rank and Sparse Decomposition: Algorithms. <br>
  <li>  Lecture 12: Convex Low-Rank and Sparse Decomposition: Analysis and Proof. <br><br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_13.pdf"> Lecture 13</a>: Convex Optimization for Structured Data: Unconstrained. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_14.pdf"> Lecture 14</a>: Convex Optimization for Structured Data: Constrained & Scalable. <br><br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_15.pdf"> Lecture 15</a>: Nonconvex Formulations: Dictionary Learning. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_16.pdf"> Lecture 16</a>: Nonconvex Methods: Dictionary Learning via L4 Maximization. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_17.pdf"> Lecture 17</a>: Nonconvex Optimization: First Order Methods. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_18.pdf"> Lecture 18</a>: Nonconvex Optimization: Power Iteration and Fixed Point. <br><br>  
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_19.pdf"> Lecture 19</a>: Nonlinear Structured Models: Sparsity in Convolution and Deconvolution. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_20.pdf"> Lecture 20</a>: Nonlinear Structured Models: Transform Invariant Low-Rank Texture. <br><br> 
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_21_22.pdf"> Lecture 21</a>: Deep Discriminative Models: The Principle of Maximal Coding Rate Reduction. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_21_22.pdf"> Lecture 22</a>: Deep Discriminative Models: White-Box Deep Convolution Networks from Rate Reduction. <br>  
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Lecture_23.pdf"> Lecture 23</a>: Deep Generative Models: Closed-Loop Data Transcription via Minimaxing Rate Reduction. <br>
</ul>
    </b>  
 
<p>
  <b>  Notes:</b> The lectures follow roughly the same order of the book chapters. Each lecture contains enough material for about an hour and half. Lectures 21 and 22 share the same (long) deck of slides. 
  Slides for Lecture 12, about analysis and proof of Principal Component Pursuit, are missing as they were not made at time the course was offered. 
  We will add it in the future, as well as keep material in all the lectures updated. (<i>This version is last updated on December 15, 2021.</i>)  
</p>
    
    <p> <b> Additional notes for discussion sessions of the course</b> (administered by a teaching assisant):</p>
<ul> 
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Discussion_1.pdf"> Discussion 1</a>: Linear Algebra and Statistics.<br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Discussion_2.pdf"> Discussion 2</a>: Facts from High-dim Statistics. <br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/Discussion_3.pdf"> Discussion 3</a>: Facts from Matrix Analysis. <br>  
</ul>
    <p> <b> Additional presentations and guest lectures</b> (by the teaching staff or colleagues):</p>
<ul>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/2018April-MaYi.pdf">Low-Dimensional Models: Algorithms and Applications</a> by Yi Ma. <br> 
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/YuxinChen_slides.pdf">Bridging Convex and Nonconvex Optimization in
          Noisy Matrix Completion</a> by Professor Yuxin Chen of Princeton University.<br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/QingQu_slides.pdf">From Shallow to Deep Representation Learning: Global Nonconvex Theory and Algorithms<a>
       by Professor Qing Qu of University of Michigan.<br>
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/YuqianZhang_slides.pdf">Sparse Blind Deconvolution: Nonconvex Geometry and Algorithm</a> 
       by Professor Yuqian Zhang of Rutgers University.<br> 
  <li> <a href="https://book-wright-ma.github.io/Lecture-Slides/MertPilanci_slides.pdf">The Hidden Convex Optimization Landscape of Deep Neural Networks</a> 
       by Professor Mert Pilanci of Stanford University.<br> 
  <li> Deep Networks and the Multiple Manifold Problem by Professor John Wright of Columbia University.<br>  
</ul>
    
</BODY>
</HTML>
